{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AC109 Project Modeling Results: Predicting the returns on Cryptocurrencies\n",
    "\n",
    "by Ali Dastjerdi, Angelina Massa, Sachin Mathur & Nate Stein\n",
    "\n",
    "### Supporting Libraries\n",
    "\n",
    "We outsourced some of the supporting code to other modules we wrote located in the main directory with the intent of having this notebook focus on the presentation of results. The supporting modules are:\n",
    "- `crypto_utils.py` contains the code we used to scrape and clean data from coinmarket.cap. It also contains the code used to wrangle/preprocess that data (saved in CSV files) into our design matrix. By separating the creation of the design matrix in its own `.py` file, we were also able to create unit tests to ensure the resulting figures match what we expected based on hand-calculated figures, which became increasingly important as we engineered more involved features.\n",
    "- `crypto_models.py` contains the code we used to iterate over multiple classification and regression models and summarize the results in tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypto_utils as cryp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "import time as time\n",
    "\n",
    "from crypto_utils import fmt_date, print_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom output options.\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pd.set_option('display.precision', 4)\n",
    "sns.set_style('white')\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "plt.rcParams['savefig.pad_inches'] = 0.05\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_STATE = 88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Design Matrix\n",
    "\n",
    "We want the construction of the design matrix to be agile enough to allow us to easily change whether we include certain features, which cryptocurrency's price return we want to forecast, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will not be using any non-crypto assets at the moment.\n",
    "\n",
    "def get_data(x_cryptos, y_crypto, test_size, kwargs):\n",
    "    design = cryp.DesignMatrix(x_cryptos=x_cryptos, y_crypto=y_crypto, **kwargs)\n",
    "    X, Y = design.get_data(lag_indicator=True)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=RAND_STATE)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_scope = ['ltc', 'xrp', 'xlm', 'eth', 'btc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CROSSVAL = 3\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline_model(x_cryptos, y_crypto, kwargs):\n",
    "    \"\"\"Return MAE on test set.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = get_data(x_cryptos, y_crypto, TEST_SIZE,\n",
    "                                                kwargs)\n",
    "    lr = LinearRegression().fit(X_train, y_train)\n",
    "    mae = metrics.mean_absolute_error(y_test, lr.predict(X_test))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine optimal rolling window for measuring changes in price and volume\n",
    "\n",
    "Ultimately we want to determine which `n_rolling_volume`, `n_rolling_price` and `n_std_window` to use going forward, as it will influence our more advanced features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished all parameter combinations in 1071.28 seconds.\r"
     ]
    }
   ],
   "source": [
    "# DataFrame to store results of trying different windows.\n",
    "\n",
    "df_results = pd.DataFrame(columns=['y', 'mae', 'n_rolling_price', \n",
    "                                   'n_rolling_volume', 'n_std_window'])\n",
    "\n",
    "params = {'n_rolling_price':None, 'n_rolling_volume':None,\n",
    "          'x_assets':[], 'n_std_window':None}\n",
    "\n",
    "n_rolling_prices = range(1, 5)\n",
    "n_rolling_volumes = range(1, 5)\n",
    "n_std_windows = range(5, 50, 5)\n",
    "\n",
    "combo_total = len(n_rolling_prices) * len(n_rolling_volumes) * len(n_std_windows)\n",
    "combo_count = 0\n",
    "\n",
    "t0 = time.time()\n",
    "for n_price in n_rolling_prices:\n",
    "    for n_vol in n_rolling_volumes:\n",
    "        for n_std in n_std_windows:\n",
    "            combo_count += 1\n",
    "            print_update('Trying param combination {}/{}...'.format(\n",
    "                combo_count, combo_total))\n",
    "            params['n_rolling_price'] = n_price\n",
    "            params['n_rolling_volume'] = n_vol\n",
    "            params['n_std_window'] = n_std\n",
    "            new_row = {'n_rolling_price': n_price,\n",
    "                       'n_rolling_volume': n_vol,\n",
    "                       'n_std_window': n_std}\n",
    "            for y_cryp in crypto_scope:\n",
    "                x_cryps = [c for c in crypto_scope if c != y_cryp]\n",
    "                new_row['y'] = y_cryp\n",
    "                new_row['mae'] = evaluate_baseline_model(x_cryps, y_cryp, \n",
    "                                                         params)\n",
    "                df_results = df_results.append(new_row, ignore_index=True)\n",
    "print_update('Finished all parameter combinations in {:.2f} seconds.'.format(\n",
    "    time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = df_results.groupby(['n_rolling_price', 'n_rolling_volume', 'n_std_window']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluating the results, we can determine that the optimal parameters are:\n",
    "- `n_rolling_price`: 1\n",
    "- `n_rolling_volume`: 1\n",
    "- `n_std_window`: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lasso(x_cryptos, y_crypto, output=True):\n",
    "    X_train, X_test, y_train, y_test = get_data(x_cryptos, y_crypto, TEST_SIZE)\n",
    "    lasso = LassoCV(n_alphas=100, cv=N_CROSSVAL, random_state=RAND_STATE)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    mae = metrics.mean_absolute_error(y_test, lasso.predict(X_test))\n",
    "    if output:\n",
    "        print('\\t{0}: {1:.2%} (alpha={2:.2f})'.format(y_crypto, mae, \n",
    "                                                      lasso.alpha_))\n",
    "    return lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Lasso Predicting Price Change for:\n",
      "\tltc: 4.08% (alpha=0.00)\n",
      "\txrp: 5.40% (alpha=0.03)\n",
      "\txlm: 5.49% (alpha=0.03)\n",
      "\teth: 4.59% (alpha=0.01)\n",
      "\tbtc: 2.98% (alpha=0.00)\n"
     ]
    }
   ],
   "source": [
    "print('MAE for Lasso Predicting Price Change for:')\n",
    "for y_cryp in crypto_scope:\n",
    "    x_cryps = [c for c in crypto_scope if c != y_cryp]\n",
    "    evaluate_lasso(x_cryps, y_cryp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_df(lasso, X_train):\n",
    "    df = pd.DataFrame(columns=['coeff', 'weight'])\n",
    "    df['coeff'] = X_train.columns.tolist()\n",
    "    df['weight'] = lasso.coef_\n",
    "    df.sort_values('weight', ascending=False, inplace=True)\n",
    "    df.set_index('coeff', inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lasso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-75b89e5adde4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lasso' is not defined"
     ]
    }
   ],
   "source": [
    "# See what weights are assigned to features.\n",
    "\n",
    "lasso = evaluate_lasso(['ltc', 'xrp', 'xlm', 'eth'], 'btc', output=False)\n",
    "feature_weights = get_features_df(lasso, X_train)\n",
    "display(feature_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_lasso = metrics.mean_absolute_error(y_test, lasso.predict(X_test))\n",
    "print('Lasso model MAE: {:.2%}'.format(mae_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xgb_model(X_train, y_train):\n",
    "    \"\"\"Iterate over a hyperparameter space and return best model on a \n",
    "    validation set reserved from input training data.\n",
    "    \"\"\"\n",
    "    # Define hyperparam space.\n",
    "    expon_distr = stats.expon(0, 50)\n",
    "    cv_params = {\n",
    "        'n_estimators': stats.randint(4, 100),\n",
    "        'max_depth': stats.randint(2, 100),\n",
    "        'learning_rate': stats.uniform(0.05, 0.95),\n",
    "        'gamma': stats.uniform(0, 10),\n",
    "        'reg_alpha': expon_distr,\n",
    "        'min_child_weight': expon_distr\n",
    "    }\n",
    "\n",
    "    # Iterate over hyperparam space.\n",
    "    xgb = XGBRegressor(nthreads=-1)  # nthreads=-1 => use max cores\n",
    "    \n",
    "    print_update('Tuning XGBRegressor hyperparams...')\n",
    "    t0 = time.time()\n",
    "    gs = RandomizedSearchCV(xgb, cv_params, n_iter=400, n_jobs=1, cv=3, \n",
    "                            random_state=88)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print_update('Finished tuning XGBRegressor in {:.0f} secs.'.format(\n",
    "        time.time() - t0))\n",
    "    \n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = build_xgb_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_xgb = metrics.mean_absolute_error(y_test, xgb.predict(X_test))\n",
    "print('XGBRegressor MAE: {:.2%}'.format(mae_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
