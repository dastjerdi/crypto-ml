{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AC109 Project Modeling Results: Predicting the returns on Cryptocurrencies\n",
    "\n",
    "by Ali Dastjerdi, Angelina Massa, Sachin Mathur & Nate Stein\n",
    "\n",
    "### Supporting Libraries\n",
    "\n",
    "We outsourced some of the supporting code to other modules we wrote located in the main directory with the intent of having this notebook focus on the presentation of results. The supporting modules are:\n",
    "- `crypto_utils.py` contains the code we used to scrape and clean data from coinmarket.cap. It also contains the code used to wrangle/preprocess that data (saved in CSV files) into our design matrix. By separating the creation of the design matrix in its own `.py` file, we were also able to create unit tests to ensure the resulting figures match what we expected based on hand-calculated figures, which became increasingly important as we engineered more involved features.\n",
    "- `crypto_models.py` contains the code we used to iterate over multiple classification and regression models and summarize the results in tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypto_utils as cryp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "import time as time\n",
    "\n",
    "from crypto_utils import fmt_date, print_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom output options.\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pd.set_option('display.precision', 4)\n",
    "sns.set_style('white')\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "plt.rcParams['savefig.pad_inches'] = 0.05\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Design Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:\n",
      "X: (949, 10)\n",
      "Y: (949,)\n"
     ]
    }
   ],
   "source": [
    "# We will not be using any non-crypto assets at the moment.\n",
    "\n",
    "x_cryptos = ['ltc', 'xrp', 'xlm', 'eth']\n",
    "y_crypto = 'btc'\n",
    "kwargs = {'n_rolling_price':1, 'n_rolling_volume':2,\n",
    "          'x_assets':[], 'n_std_window':30}\n",
    "design = cryp.DesignMatrix(x_cryptos=x_cryptos, y_crypto=y_crypto, **kwargs)\n",
    "X, Y = design.get_data()\n",
    "print('Dimensions:')\n",
    "print('X: {}'.format(X.shape))\n",
    "print('Y: {}'.format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate into train/test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline LinearRegression model MAE: 3.00%\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "mae_lr = metrics.mean_absolute_error(y_test, lr.predict(X_test))\n",
    "print('Baseline LinearRegression model MAE: {:.2%}'.format(mae_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xgb_model(X_train, y_train):\n",
    "    \"\"\"Iterate over a hyperparameter space and return best model on a \n",
    "    validation set reserved from input training data.\n",
    "    \"\"\"\n",
    "    # Define hyperparam space.\n",
    "    expon_distr = stats.expon(0, 50)\n",
    "    cv_params = {\n",
    "        'n_estimators': stats.randint(4, 100),\n",
    "        'max_depth': stats.randint(2, 100),\n",
    "        'learning_rate': stats.uniform(0.05, 0.95),\n",
    "        'gamma': stats.uniform(0, 10),\n",
    "        'reg_alpha': expon_distr,\n",
    "        'min_child_weight': expon_distr\n",
    "    }\n",
    "\n",
    "    # Iterate over hyperparam space.\n",
    "    xgb = XGBRegressor(nthreads=-1)  # nthreads=-1 => use max cores\n",
    "    \n",
    "    print_update('Tuning XGBRegressor hyperparams...')\n",
    "    t0 = time.time()\n",
    "    gs = RandomizedSearchCV(xgb, cv_params, n_iter=400, n_jobs=1, cv=4, \n",
    "                            random_state=88)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print_update('Finished tuning XGBRegressor in {:.0f} secs.'.format(\n",
    "        time.time() - t0))\n",
    "    \n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tuning XGBRegressor in 14 secs.\r"
     ]
    }
   ],
   "source": [
    "xgb = build_xgb_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor MAE: 2.98%\n"
     ]
    }
   ],
   "source": [
    "mae_xgb = metrics.mean_absolute_error(y_test, xgb.predict(X_test))\n",
    "print('XGBRegressor MAE: {:.2%}'.format(mae_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
